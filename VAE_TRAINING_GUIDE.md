

# ğŸ¯ Î²-VAE Training Guide

Complete guide for training Î²-VAE with proper preprocessing and evaluation.

---

## âœ… **Preprocessing Steps (Run Once)**

### **Step 1: Install Dependencies**

```bash
source /opt/anaconda3/bin/activate cam16

# Install PyTorch (if needed)
pip install torch torchvision

# Install additional packages
pip install albumentations pytorch-msssim
```

### **Step 2: Create Reference Tile & Compute Stats**

```bash
# Option A: Automatic (recommended)
bash setup_vae.sh

# Option B: Manual
python stain_utils.py --csv final_dataset/dataset.csv --output reference_tile.npy --n-samples 10
python compute_normalization_stats.py --csv final_dataset/dataset.csv --split train --max-samples 10000
```

**Output:**
- `reference_tile.npy` - For Macenko stain normalization
- `normalization_stats.npy` - RGB mean/std for normalization

**Stats computed:**
```
Mean (R, G, B): [0.182, 0.182, 0.182]
Std  (R, G, B): [0.427, 0.427, 0.427]
```

---

## ğŸ‹ï¸ **Training**

### **Basic Training** (Recommended Starting Point)

```bash
python train_vae.py \
  --z-dim 128 \
  --beta 1.0 \
  --epochs 50 \
  --batch-size 128
```

**This uses:**
- âœ… 147,471 training normals (train + val combined)
- âœ… Stain normalization (Macenko â†’ Reinhard fallback)
- âœ… RGB normalization (PCam mean/std)
- âœ… Data augmentation (flips, rotations, color jitter)
- âœ… Î²-VAE loss: L = 0.6*L1 + 0.4*(1-SSIM) + 1.0*KL
- âœ… KL warm-up (0â†’1.0 over 10 epochs)

**Time:** 2-4 hours on M1/M2 Mac (MPS)

---

### **Grid Search** (Explore Hyperparameters)

```bash
# Configuration 1: z_dim=64, Î²=1
python train_vae.py --z-dim 64 --beta 1.0 --epochs 50 --output vae_z64_b1.pth

# Configuration 2: z_dim=128, Î²=1 (recommended)
python train_vae.py --z-dim 128 --beta 1.0 --epochs 50 --output vae_z128_b1.pth

# Configuration 3: z_dim=128, Î²=3 (more regularization)
python train_vae.py --z-dim 128 --beta 3.0 --epochs 50 --output vae_z128_b3.pth
```

---

## ğŸ“Š **Complete Preprocessing Pipeline**

### **What Happens to Each Image:**

```
1. Load RGB image (96Ã—96, uint8)
         â†“
2. Stain normalization (Macenko to reference tile)
         â†“
3. Scale to [0, 1] (divide by 255)
         â†“
4. Data augmentation (train only):
   - Horizontal/vertical flips (50%)
   - 90Â° rotations (50%)
   - Brightness/contrast Â±10% (50%)
   - Saturation Â±5% (50%)
   - Hue Â±2Â° (50%)
         â†“
5. To PyTorch tensor [3, 96, 96]
         â†“
6. RGB normalization:
   normalized = (img - mean) / std
   mean = [0.182, 0.182, 0.182]
   std  = [0.427, 0.427, 0.427]
         â†“
7. Feed to Î²-VAE
```

---

## ğŸ¯ **Model Architecture**

### **Encoder** (96Ã—96 â†’ z_dim)

```
Input: [B, 3, 96, 96]
  â†“ Conv2d(3â†’64, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 64, 48, 48]
  â†“ Conv2d(64â†’128, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 128, 24, 24]
  â†“ Conv2d(128â†’256, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 256, 12, 12]
  â†“ Conv2d(256â†’256, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 256, 6, 6]
  â†“ Flatten + Linear â†’ Î¼, log(ÏƒÂ²)
Output: [B, z_dim], [B, z_dim]
```

### **Decoder** (z_dim â†’ 96Ã—96)

```
Input: z ~ N(Î¼, ÏƒÂ²)  [B, z_dim]
  â†“ Linear(z_dim â†’ 256*6*6) + Reshape
  [B, 256, 6, 6]
  â†“ ConvTranspose2d(256â†’256, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 256, 12, 12]
  â†“ ConvTranspose2d(256â†’128, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 128, 24, 24]
  â†“ ConvTranspose2d(128â†’64, k=4, s=2, p=1) + GroupNorm + LeakyReLU
  [B, 64, 48, 48]
  â†“ ConvTranspose2d(64â†’3, k=4, s=2, p=1) + Sigmoid
Output: [B, 3, 96, 96]
```

---

## ğŸ“‰ **Loss Function**

### **Î²-VAE Loss**

```
L = Î»â‚ * L1 + Î»â‚› * (1 - SSIM) + Î² * KL

Where:
- L1: Mean absolute error (pixel-wise)
- SSIM: Structural similarity (perceptual quality)
- KL: KL divergence KL(q(z|x) || N(0,1))

Parameters:
- Î»â‚ = 0.6 (L1 weight)
- Î»â‚› = 0.4 (SSIM weight)
- Î² âˆˆ {1, 3} (KL weight)
```

### **KL Warm-up Schedule**

```
Î²(epoch) = Î²_max * min(1.0, epoch / 10)

Epoch 0:  Î² = 0.000
Epoch 1:  Î² = 0.100
Epoch 2:  Î² = 0.200
...
Epoch 9:  Î² = 0.900
Epoch 10+: Î² = 1.000 (or 3.000)
```

**Why warm-up?** Prevents KL collapse (posterior = prior), allows decoder to learn before regularization kicks in.

---

## ğŸ”§ **Quality Filters (Built-in)**

### **HSV Tissue Detection**
```python
# Convert to HSV
# Check saturation > 0.07
tissue_mask = (saturation > 0.07)
tissue_frac = tissue_mask.sum() / total_pixels

# Reject if tissue_frac < 0.65
```

### **Blur Detection**
```python
# Laplacian variance
blur_var = cv2.Laplacian(gray, cv2.CV_64F).var()

# Reject if blur_var < 30
```

**Note:** Test set already pre-filtered, so these are optional during training.

---

## ğŸ“ˆ **Expected Training Behavior**

### **Good Training**
```
Epoch  1: Loss=0.150, Recon=0.145, KL=50.0, Î²=0.100
Epoch  5: Loss=0.080, Recon=0.070, KL=30.0, Î²=0.500
Epoch 10: Loss=0.045, Recon=0.035, KL=10.0, Î²=1.000
Epoch 20: Loss=0.020, Recon=0.015, KL=5.0,  Î²=1.000
Epoch 50: Loss=0.010, Recon=0.008, KL=2.0,  Î²=1.000
```

### **Signs of Good Convergence**
- âœ… Loss decreases smoothly
- âœ… Recon loss reaches ~0.008-0.015
- âœ… KL stabilizes around 2-5 (not 0, not 100)
- âœ… Reconstructions look sharp and realistic

### **Warning Signs**
- âš ï¸ KL â†’ 0 (posterior collapse, increase Î²)
- âš ï¸ KL â†’ 100+ (no learning, decrease Î²)
- âš ï¸ Recon stuck high (>0.05, train longer or increase z_dim)

---

## ğŸš€ **After Training**

### **Run Inference**

```bash
python run_inference_vae.py \
  --model vae_best.pth \
  --test-csv test_set_heatmaps/test_set.csv
```

**Expected:**
- Normal tissue: low error (~0.01-0.05)
- Tumor tissue: high error (~0.10-0.30)
- Ratio: 2-5Ã— higher for tumors

### **Generate Heatmaps**

```bash
python generate_heatmaps.py \
  --test-csv test_set_heatmaps/test_set.csv \
  --scores-csv reconstruction_scores.csv
```

### **Compute Metrics**

```bash
python compute_metrics.py \
  --test-csv test_set_heatmaps/test_set.csv \
  --scores-csv reconstruction_scores.csv
```

---

## ğŸ¯ **Hyperparameter Recommendations**

### **z_dim (Latent Dimension)**
- **64**: Faster training, more regularization, may lose details
- **128**: Recommended - good balance
- **256**: More capacity, but may overfit on normals

### **Î² (KL Weight)**
- **Î²=1.0**: Standard VAE, good reconstruction quality
- **Î²=3.0**: More disentangled, may improve anomaly detection
- **Î²>5.0**: Too much regularization, poor reconstructions

### **Best Config for Tumor Detection**
```bash
python train_vae.py --z-dim 128 --beta 1.0 --epochs 50
```

This gives good reconstruction quality while maintaining regularization.

---

## ğŸ”¬ **Advanced: Why Î²-VAE for Tumor Detection?**

### **Advantages over Regular AE**

1. **Probabilistic**: Captures uncertainty (useful for anomalies)
2. **Regularized**: Less overfitting to normal tissue
3. **Disentangled**: Î²>1 encourages independent latent factors
4. **Robust**: Better generalization to unseen patterns

### **Reconstruction Error as Anomaly Score**

**Normal tissue** (in training distribution):
- Model has seen similar patterns
- Low reconstruction error
- Low KL divergence

**Tumor tissue** (out of distribution):
- Model hasn't seen these patterns
- High reconstruction error
- Latent encoding struggles â†’ high error

---

## ğŸ’¡ **Troubleshooting**

### **Issue: Loss not decreasing**
- Check learning rate (try 1e-4 if 1e-3 too high)
- Increase warmup epochs (15 instead of 10)
- Check data loading (visualize a batch)

### **Issue: KL â†’ 0 (posterior collapse)**
- Increase Î² (try 3.0 instead of 1.0)
- Decrease Î»_L1 and Î»_SSIM slightly
- Extend warmup (15-20 epochs)

### **Issue: Poor reconstruction quality**
- Decrease Î² (try 0.5 or 1.0 instead of 3.0)
- Increase z_dim (128 â†’ 256)
- Train longer (100 epochs)

### **Issue: Low tumor/normal separation**
- Try Î²=3.0 (more regularization)
- Check stain normalization is working
- Visualize reconstructions to debug

---

## ğŸ“Š **Monitoring Training**

### **Check Reconstructions**

After training, visualize some samples:

```python
import torch
import matplotlib.pyplot as plt
import numpy as np

# Load model
checkpoint = torch.load('vae_best.pth')
model = BetaVAE(z_dim=checkpoint['config']['z_dim'])
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Load a sample
from dataset import TissueDataset
dataset = TissueDataset('final_dataset/dataset.csv', split='train', augment=False)
img, _ = dataset[0]

# Reconstruct
with torch.no_grad():
    img_batch = img.unsqueeze(0)
    recon, mu, logvar = model(img_batch)
    
# Denormalize for visualization
mean = np.array(checkpoint['config']['mean'])
std = np.array(checkpoint['config']['std'])

img_vis = img.cpu().numpy().transpose(1, 2, 0) * std + mean
recon_vis = recon[0].cpu().numpy().transpose(1, 2, 0) * std + mean

# Plot
fig, axes = plt.subplots(1, 2, figsize=(8, 4))
axes[0].imshow(np.clip(img_vis, 0, 1))
axes[0].set_title('Original')
axes[1].imshow(np.clip(recon_vis, 0, 1))
axes[1].set_title('Reconstructed')
plt.tight_layout()
plt.savefig('reconstruction_sample.png')
print("âœ“ Saved: reconstruction_sample.png")
```

---

## ğŸ¯ **Expected Performance**

### **Training Metrics**
- Final loss: 0.010-0.020
- Recon loss: 0.008-0.015
- KL divergence: 2-5

### **Evaluation Metrics**
- Patch-level AUC: > 0.75 (good), > 0.85 (excellent)
- PR-AUC: > 0.70 (good), > 0.80 (excellent)
- FROC: > 0.60 (good), > 0.75 (excellent)
- Tumor/Normal ratio: 2-5Ã— higher error for tumors

---

## ğŸ“ **Files Created**

```
Preprocessing:
  âœ“ reference_tile.npy          # Stain normalization reference
  âœ“ normalization_stats.npy     # RGB mean/std

Training:
  âœ“ vae_best.pth                # Best model checkpoint

Inference:
  âœ“ reconstruction_scores.csv   # Tile-level errors

Evaluation:
  âœ“ heatmaps/*.png              # Visualizations
  âœ“ evaluation_summary.csv      # All metrics
  âœ“ froc_curve.png              # FROC plot
```

---

## ğŸš€ **Complete Workflow**

```bash
# 1. Setup (once)
bash setup_vae.sh

# 2. Train Î²-VAE
python train_vae.py --z-dim 128 --beta 1.0 --epochs 50

# 3. Run inference
python run_inference_vae.py \
  --model vae_best.pth \
  --test-csv test_set_heatmaps/test_set.csv

# 4. Generate heatmaps
python generate_heatmaps.py \
  --test-csv test_set_heatmaps/test_set.csv \
  --scores-csv reconstruction_scores.csv

# 5. Compute metrics
python compute_metrics.py \
  --test-csv test_set_heatmaps/test_set.csv \
  --scores-csv reconstruction_scores.csv
```

**Total time:** 3-5 hours (mostly training)

---

## âœ… **What You Get**

### **Training**
- Trained Î²-VAE that learned normal tissue morphology
- Model checkpoint with all hyperparameters
- Training curves (can add TensorBoard if desired)

### **Evaluation**
- Reconstruction errors for 166k test tiles
- Heatmaps for 8 complete slides
- Comprehensive metrics (7 different metrics)
- Publication-ready figures

### **For Presentation**
- 4-panel heatmap visualizations
- FROC curve
- Metrics table
- Clear tumor/normal separation

---

## ğŸ’¡ **Key Advantages of This Pipeline**

1. **Stain Normalization**: Handles color variability across slides/scanners
2. **Î²-VAE**: Better than regular AE for anomaly detection
3. **Proper Augmentation**: Improves robustness
4. **KL Warm-up**: Prevents posterior collapse
5. **Quality Filtering**: Ensures clean data
6. **Comprehensive Metrics**: Multiple evaluation angles

---

## ğŸ¨ **Example Results**

### **Reconstruction Errors**
```
Normal tissue:  0.015 Â± 0.005  (well reconstructed)
Tumor tissue:   0.045 Â± 0.020  (anomalies, poor reconstruction)
Ratio:          3.0Ã— higher for tumors
```

### **Classification Metrics**
```
AUC-ROC:     0.82
PR-AUC:      0.78
F1-Score:    0.74
Dice:        0.74
IoU:         0.59
FROC:        0.68
```

---

## ğŸš€ **Ready to Start!**

```bash
# Just run:
bash setup_vae.sh

# Then:
python train_vae.py --z-dim 128 --beta 1.0 --epochs 50
```

**Your pipeline is production-ready with state-of-the-art preprocessing!** ğŸ‰

